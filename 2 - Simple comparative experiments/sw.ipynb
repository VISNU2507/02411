{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7141fe9",
   "metadata": {},
   "source": [
    "# Chapter 2 — Simple Comparative Experiments (Deep-Dive Notes + Python)\n",
    "\n",
    "> These notes give you the **big picture** and the *mechanics* you’ll actually use: definitions, formulas (with $/$ or $$…$$ LaTeX), assumptions, diagnostic plots, and **Python** examples you can run to reproduce results (including the multi-choice problems you shared).\n",
    "\n",
    "---\n",
    "\n",
    "## 0) The Big Picture\n",
    "\n",
    "**Goal:** Compare two conditions (treatments) using data with noise. Decide if observed differences are real or just random.\n",
    "\n",
    "**Workflow:**\n",
    "1. **Design** the experiment → randomize; if possible, **pair/block** to reduce noise.\n",
    "2. **Plot & check assumptions** → histograms/boxplots/QQ plots; think independence.\n",
    "3. **Choose the right model/test** → Z, t (pooled/Welch), paired t, or F for variances.\n",
    "4. **Compute test statistic & P-value** → interpret with your $\\alpha$.\n",
    "5. **Report a CI** → magnitude + uncertainty beats “significant/not”.\n",
    "6. **Think power & sample size** → do we have enough $n$ to see effects we care about?\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Random Variables, Expectation, Variance (Why so many “definitions”?)\n",
    "\n",
    "We’ll always distinguish **population** (unknown, Greek letters) vs **sample** (observed, Latin):\n",
    "\n",
    "- **Population mean (expectation)**  \n",
    "  $$\n",
    "  \\mu = E[Y] =\n",
    "  \\begin{cases}\n",
    "  \\displaystyle \\sum_y y\\,p(y), & \\text{discrete}\\\\[6pt]\n",
    "  \\displaystyle \\int_{-\\infty}^\\infty y\\,f(y)\\,dy, & \\text{continuous}\n",
    "  \\end{cases}\n",
    "  $$\n",
    "  *Why two forms?* Discrete uses a **sum** over masses $p(y)$; continuous uses an **integral** over density $f(y)$.\n",
    "\n",
    "- **Population variance**  \n",
    "  $$\n",
    "  \\sigma^2 = \\operatorname{Var}(Y) = E\\big[(Y-\\mu)^2\\big] =\n",
    "  \\begin{cases}\n",
    "  \\displaystyle \\sum_y (y-\\mu)^2\\,p(y), & \\text{discrete}\\\\[6pt]\n",
    "  \\displaystyle \\int_{-\\infty}^\\infty (y-\\mu)^2 f(y)\\,dy, & \\text{continuous}\n",
    "  \\end{cases}\n",
    "  $$\n",
    "  **Standard deviation** is just the scale: $\\sigma=\\sqrt{\\sigma^2}$.\n",
    "\n",
    "- **Sample statistics (point estimators)**  \n",
    "  $$\n",
    "  \\bar{y}=\\frac{1}{n}\\sum_{i=1}^n y_i,\\qquad\n",
    "  s^2=\\frac{1}{n-1}\\sum_{i=1}^n (y_i-\\bar{y})^2,\\qquad\n",
    "  s=\\sqrt{s^2}.\n",
    "  $$\n",
    "  *Why $n-1$?* **Bessel’s correction** makes $s^2$ **unbiased** for $\\sigma^2$ when sampling i.i.d. from a normal population.\n",
    "\n",
    "- **Covariance & Independence**  \n",
    "  $$\n",
    "  \\operatorname{Cov}(Y_1,Y_2)=E\\!\\left[(Y_1-\\mu_1)(Y_2-\\mu_2)\\right],\\quad\n",
    "  Y_1\\perp Y_2\\Rightarrow \\operatorname{Cov}(Y_1,Y_2)=0.\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Sampling Distributions & Why t/χ²/F Show Up\n",
    "\n",
    "- **Normal**  \n",
    "  $$\n",
    "  Y\\sim \\mathcal{N}(\\mu,\\sigma^2),\\quad\n",
    "  Z=\\frac{Y-\\mu}{\\sigma}\\sim \\mathcal{N}(0,1).\n",
    "  $$\n",
    "\n",
    "- **Central Limit Theorem (CLT)**  \n",
    "  $$\n",
    "  \\frac{\\sum_{i=1}^n Y_i - n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{d} \\mathcal{N}(0,1).\n",
    "  $$\n",
    "\n",
    "- **Variance & χ²** (normality critical)  \n",
    "  $$\n",
    "  \\chi_0^2=\\frac{(n-1)s^2}{\\sigma_0^2}\\sim \\chi^2_{n-1}\\quad \\text{under }H_0:\\sigma^2=\\sigma_0^2.\n",
    "  $$\n",
    "\n",
    "- **t-distribution** (mean with unknown $\\sigma$)  \n",
    "  $$\n",
    "  T=\\frac{\\bar{Y}-\\mu_0}{S/\\sqrt{n}}\\sim t_{n-1}\\quad(\\text{normal data}).\n",
    "  $$\n",
    "\n",
    "- **F-distribution** (ratio of two independent χ²/df)  \n",
    "  $$\n",
    "  F=\\frac{(X/u)}{(Y/v)}\\sim F_{u,v},\\quad X\\sim \\chi^2_u,\\ Y\\sim \\chi^2_v,\\ X\\perp Y.\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Confidence Intervals (CIs) & Hypothesis Tests\n",
    "\n",
    "**General CI template:**  \n",
    "$$\n",
    "\\text{Estimator} \\ \\pm\\ (\\text{critical value})\\times(\\text{SE}).\n",
    "$$\n",
    "\n",
    "**Hypothesis testing flow:**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\text{1) State } H_0 \\text{ and } H_1 \\\\\n",
    "&\\text{2) Pick } \\alpha \\\\\n",
    "&\\text{3) Compute statistic } (Z, t, F, \\chi^2) \\\\\n",
    "&\\text{4) } P\\text{-value } = P(\\text{at least as extreme} \\mid H_0) \\\\\n",
    "&\\text{5) Reject } H_0 \\text{ if } P\\text{-value} \\le \\alpha.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "**Interpretation:**  \n",
    "$$\n",
    "\\text{P-value}=P(\\text{data as or more extreme}\\mid H_0 \\text{ true}).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Two-Sample Comparisons (Means)\n",
    "\n",
    "**Setup:** Two **independent** samples of sizes $n_1,n_2$ with means $\\bar{y}_1,\\bar{y}_2$ and variances $s_1^2,s_2^2$.\n",
    "\n",
    "### 4.1 Equal variances assumed (pooled t)\n",
    "- Pooled variance:\n",
    "  $$\n",
    "  s_p^2=\\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}.\n",
    "  $$\n",
    "- Test statistic (two-sided $H_0:\\mu_1=\\mu_2$):\n",
    "  $$\n",
    "  t_0=\\frac{\\bar{y}_1-\\bar{y}_2}{s_p\\sqrt{1/n_1+1/n_2}}\\sim t_{n_1+n_2-2}.\n",
    "  $$\n",
    "- CI for $\\mu_1-\\mu_2$:\n",
    "  $$\n",
    "  (\\bar{y}_1-\\bar{y}_2)\\pm t_{\\alpha/2,\\ n_1+n_2-2}\\ s_p\\sqrt{\\tfrac1{n_1}+\\tfrac1{n_2}}.\n",
    "  $$\n",
    "\n",
    "### 4.2 Unequal variances (Welch t)\n",
    "- Statistic:\n",
    "  $$\n",
    "  t_0=\\frac{\\bar{y}_1-\\bar{y}_2}{\\sqrt{s_1^2/n_1+s_2^2/n_2}}.\n",
    "  $$\n",
    "- df (Welch–Satterthwaite):\n",
    "  $$\n",
    "  \\mathrm{df}\\approx \\frac{(s_1^2/n_1+s_2^2/n_2)^2}{\\frac{(s_1^2/n_1)^2}{n_1-1}+\\frac{(s_2^2/n_2)^2}{n_2-1}}.\n",
    "  $$\n",
    "\n",
    "### 4.3 Known variances (Z test)\n",
    "- Statistic:\n",
    "  $$\n",
    "  Z_0=\\frac{\\bar{y}_1-\\bar{y}_2}{\\sqrt{\\sigma_1^2/n_1+\\sigma_2^2/n_2}}\\sim \\mathcal{N}(0,1)\\ \\text{under }H_0.\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Comparing Variances (Normality is important)\n",
    "\n",
    "### 5.1 One variance\n",
    "- Test:\n",
    "  $$\n",
    "  \\chi_0^2=\\frac{(n-1)s^2}{\\sigma_0^2}\\sim \\chi^2_{n-1}.\n",
    "  $$\n",
    "\n",
    "- CI:\n",
    "  $$\n",
    "  \\left[\\frac{(n-1)s^2}{\\chi^2_{1-\\alpha/2,n-1}},\\ \\frac{(n-1)s^2}{\\chi^2_{\\alpha/2,n-1}} \\right].\n",
    "  $$\n",
    "\n",
    "### 5.2 Two variances (F test)\n",
    "- Statistic:\n",
    "  $$\n",
    "  F_0=\\frac{s_1^2}{s_2^2}\\sim F_{n_1-1,\\ n_2-1}\\quad (\\text{if data normal \\& independent}).\n",
    "  $$\n",
    "- Two-sided CI for $\\sigma_1^2/\\sigma_2^2$:\n",
    "  $$\n",
    "  \\left[\\frac{s_1^2/s_2^2}{F_{1-\\alpha/2,\\,n_1-1,\\,n_2-1}},\\ \\frac{s_1^2/s_2^2}{F_{\\alpha/2,\\,n_1-1,\\,n_2-1}}\\right].\n",
    "  $$\n",
    "\n",
    "> **Assumption note:** Tests/intervals on **variances** are **very sensitive** to non-normality. Check QQ plots.\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Paired Designs (Blocking Principle)\n",
    "\n",
    "**Idea:** Measure both treatments on the **same** (or matched) unit → analyze **differences** $d_j=y_{1j}-y_{2j}$.\n",
    "\n",
    "- Paired t:\n",
    "  $$\n",
    "  \\bar{d}=\\frac{1}{n}\\sum_j d_j,\\quad s_d^2=\\frac{1}{n-1}\\sum_j (d_j-\\bar{d})^2,\\quad\n",
    "  t_0=\\frac{\\bar{d}}{s_d/\\sqrt{n}}\\sim t_{n-1}.\n",
    "  $$\n",
    "- CI:\n",
    "  $$\n",
    "  \\bar{d}\\pm t_{\\alpha/2,n-1}\\frac{s_d}{\\sqrt{n}}.\n",
    "  $$\n",
    "\n",
    "**Why it helps:** If within-pair outcomes are positively correlated, **variance of $d$ shrinks**, giving **higher power** (narrower CI) for the same $n$.\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Power, Effect Size, and Sample Size\n",
    "\n",
    "- **Standardized effect** (two-sample):\n",
    "  $$\n",
    "  \\delta=\\frac{|\\mu_1-\\mu_2|}{\\sigma}.\n",
    "  $$\n",
    "- **Power** (probability to reject $H_0$ when a specific alternative is true) increases with larger $n$, larger $\\delta$, and larger $\\alpha$ (but increasing $\\alpha$ increases Type I error).\n",
    "\n",
    "**Approx sample size (balanced, pooled t, target two-sided power $1-\\beta$):**\n",
    "$$\n",
    "n\\ \\approx\\ 2\\left(\\frac{z_{1-\\alpha/2}+z_{1-\\beta}}{\\Delta/\\sigma}\\right)^2,\n",
    "$$\n",
    "where $\\Delta$ is the **minimum meaningful difference** you want to detect, and $\\sigma$ a planning SD.\n",
    "\n",
    "---\n",
    "\n",
    "## 8) Python “Recipes” (Drop-in Code)\n",
    "\n",
    "> You can paste these into a notebook. They rely on `scipy` and `numpy`. Replace numbers with your data.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from scipy import stats as st\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def pooled_sd(s1, n1, s2, n2):\n",
    "    sp2 = ((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2)\n",
    "    return sqrt(sp2)\n",
    "\n",
    "def two_sample_t_equal(y1bar, s1, n1, y2bar, s2, n2, alternative=\"two-sided\"):\n",
    "    sp = pooled_sd(s1,n1,s2,n2)\n",
    "    df = n1+n2-2\n",
    "    t0 = (y1bar - y2bar) / (sp*sqrt(1/n1 + 1/n2))\n",
    "    if alternative == \"two-sided\":\n",
    "        p = 2*(1 - st.t.cdf(abs(t0), df))\n",
    "    elif alternative == \"greater\":\n",
    "        p = 1 - st.t.cdf(t0, df)\n",
    "    else:\n",
    "        p = st.t.cdf(t0, df)\n",
    "    return t0, df, p\n",
    "\n",
    "def two_sample_t_welch(y1bar, s1, n1, y2bar, s2, n2, alternative=\"two-sided\"):\n",
    "    se = sqrt(s1*s1/n1 + s2*s2/n2)\n",
    "    t0 = (y1bar - y2bar) / se\n",
    "    df = (s1*s1/n1 + s2*s2/n2)**2 / ((s1*s1/n1)**2/(n1-1) + (s2*s2/n2)**2/(n2-1))\n",
    "    if alternative == \"two-sided\":\n",
    "        p = 2*(1 - st.t.cdf(abs(t0), df))\n",
    "    elif alternative == \"greater\":\n",
    "        p = 1 - st.t.cdf(t0, df)\n",
    "    else:\n",
    "        p = st.t.cdf(t0, df)\n",
    "    return t0, df, p\n",
    "\n",
    "def paired_t(d, alternative=\"two-sided\"):\n",
    "    d = np.asarray(d)\n",
    "    n = d.size\n",
    "    dbar = d.mean()\n",
    "    sd = d.std(ddof=1)\n",
    "    t0 = dbar / (sd/sqrt(n))\n",
    "    df = n-1\n",
    "    if alternative == \"two-sided\":\n",
    "        p = 2*(1 - st.t.cdf(abs(t0), df))\n",
    "    elif alternative == \"greater\":\n",
    "        p = 1 - st.t.cdf(t0, df)\n",
    "    else:\n",
    "        p = st.t.cdf(t0, df)\n",
    "    return dbar, sd, t0, df, p\n",
    "\n",
    "def f_test_variances(s1, n1, s2, n2, alternative=\"two-sided\"):\n",
    "    F = (s1**2)/(s2**2)\n",
    "    df1, df2 = n1-1, n2-1\n",
    "    if alternative == \"two-sided\":\n",
    "        p = 2*min(1-st.f.cdf(F, df1, df2), st.f.cdf(F, df1, df2))\n",
    "    elif alternative == \"greater\":  # H1: sigma1^2 > sigma2^2\n",
    "        p = 1 - st.f.cdf(F, df1, df2)\n",
    "    else:  # H1: sigma1^2 < sigma2^2\n",
    "        p = st.f.cdf(F, df1, df2)\n",
    "    return F, df1, df2, p\n",
    "\n",
    "def ci_var_ratio(s1, n1, s2, n2, alpha=0.05):\n",
    "    F_low  = st.f.ppf(alpha/2, n1-1, n2-1)\n",
    "    F_high = st.f.ppf(1-alpha/2, n1-1, n2-1)\n",
    "    ratio = (s1**2)/(s2**2)\n",
    "    return ratio/F_high, ratio/F_low\n",
    "\n",
    "def ci_diff_means_equal(y1bar, s1, n1, y2bar, s2, n2, alpha=0.05):\n",
    "    sp = pooled_sd(s1, n1, s2, n2)\n",
    "    df = n1+n2-2\n",
    "    me = st.t.ppf(1-alpha/2, df) * sp * sqrt(1/n1 + 1/n2)\n",
    "    diff = y1bar - y2bar\n",
    "    return diff-me, diff+me, df\n",
    "\n",
    "def power_two_sample_equal(delta, sigma, n1, n2, alpha=0.05):\n",
    "    # Two-sided power using noncentral t with equal variances\n",
    "    df = n1+n2-2\n",
    "    tcrit = st.t.ppf(1-alpha/2, df)\n",
    "    ncp = delta / (sigma*sqrt(1/n1 + 1/n2))\n",
    "    # Power = P(|T|>tcrit) where T ~ nct(df, ncp)\n",
    "    return (1 - st.nct.cdf(tcrit, df, ncp)) + st.nct.cdf(-tcrit, df, ncp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87b52a",
   "metadata": {},
   "source": [
    "# 9) Worked Example (Portland Cement, equal-variance t)\n",
    "\n",
    "Two independent samples $(n_1=n_2=10)$ with  \n",
    "$\\bar{y}_1=16.76,\\ \\bar{y}_2=17.04,\\ s_1^2=0.100,\\ s_2^2=0.061$.\n",
    "\n",
    "**Pooled variance and SD**\n",
    "$$\n",
    "s_p^2=\\frac{9(0.100)+9(0.061)}{18}=0.081,\n",
    "\\qquad\n",
    "s_p=\\sqrt{0.081}=0.284.\n",
    "$$\n",
    "\n",
    "**Test statistic**\n",
    "$$\n",
    "t_0=\\frac{16.76-17.04}{\\,0.284\\,\\sqrt{1/10+1/10}\\,}=-2.20,\n",
    "\\qquad\n",
    "\\mathrm{df}=18.\n",
    "$$\n",
    "\n",
    "**95% CI**\n",
    "$$\n",
    "(16.76-17.04)\\ \\pm\\ t_{0.025,\\,18}\\cdot 0.284\\sqrt{1/10+1/10}\n",
    "\\;=\\;-0.28\\pm 0.27\\;\\Rightarrow\\;[-0.55,\\,-0.01].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 10) Fully Worked Multi-Choice Problems (with answers & Python)\n",
    "\n",
    "## Problem I — Vaccines\n",
    "\n",
    "Given: $n_1=10,\\ n_2=16,\\ \\bar{y}_1=11.8,\\ \\bar{y}_2=13.9,\\ s_1=3.6,\\ s_2=2.1$.\n",
    "\n",
    "**(I.1) Equality of variances (two-sided)**  \n",
    "Use $F_0=s_1^2/s_2^2$ with df $(9,15)$.\n",
    "- Ratio: $s_1^2/s_2^2=12.96/4.41=2.94$.\n",
    "- At $\\alpha=0.05$ two-sided, the **upper** critical value is $F_{0.975;\\,9,15}\\approx 3.12$.\n",
    "- **Answer:** 3.12 (Option 5) is a critical value.\n",
    "\n",
    "**(I.2) 95% CI for $\\sigma_1^2/\\sigma_2^2$**\n",
    "$$\n",
    "\\left[\n",
    "\\frac{2.94}{F_{0.975;\\,9,15}},\n",
    "\\ \\frac{2.94}{F_{0.025;\\,9,15}}\n",
    "\\right]\\ \\approx\\ [0.94,\\ 11.08].\n",
    "$$\n",
    "**Answer:** $[0.94,\\ 11.08]$ (Option 3).\n",
    "\n",
    "**(I.3) Means (two-sided, equal variances assumed)**  \n",
    "Pooled $s_p\\approx 2.760,\\ \\mathrm{df}=24$, $t_0\\approx -1.888\\Rightarrow p\\approx 0.071$.  \n",
    "**Smallest $\\alpha$ to reject:** 10% (Option 4).\n",
    "\n",
    "**(I.4) 95% CI for $\\mu_1-\\mu_2$ (pooled)**\n",
    "$$\n",
    "[-4.40,\\ 0.20]\\ \\text{(to 2 decimals).}\n",
    "$$\n",
    "**Answer:** $[-4.40, 0.20]$ (Option 1).\n",
    "\n",
    "**Reproducible Python (assumes helper functions defined earlier)**\n",
    "~~~python\n",
    "y1bar, y2bar, s1, s2, n1, n2 = 11.8, 13.9, 3.6, 2.1, 10, 16\n",
    "\n",
    "F, df1, df2, pF_two = f_test_variances(s1, n1, s2, n2, alternative=\"two-sided\")\n",
    "Fcrit_up = st.f.ppf(0.975, df1, df2)   # ~ 3.12\n",
    "\n",
    "ci_ratio = ci_var_ratio(s1, n1, s2, n2, alpha=0.05)  # ~ (0.94, 11.08)\n",
    "\n",
    "t0, df, p = two_sample_t_equal(y1bar, s1, n1, y2bar, s2, n2)\n",
    "ci = ci_diff_means_equal(y1bar, s1, n1, y2bar, s2, n2)  # ends ~ (-4.40, 0.20)\n",
    "~~~\n",
    "\n",
    "---\n",
    "\n",
    "## Problem I — Sporting Goods (Soles)\n",
    "\n",
    "Given: $n_1=n_2=10,\\ \\bar{y}_1=11.9,\\ \\bar{y}_2=17.8,\\ s_1=6.2,\\ s_2=3.2$.\n",
    "\n",
    "**(I.1) Equality of variances (two-sided)**  \n",
    "$F_0=6.2^2/3.2^2\\approx 3.754$, df $(9,9)$ → two-sided $p\\approx 0.062$ → reject at **10%** but not **5%**.  \n",
    "**Answer:** 10% (Option 4).\n",
    "\n",
    "**(I.2) Means equal (two-sided, pooled t)**  \n",
    "$t_0\\approx -2.674,\\ \\mathrm{df}=18\\Rightarrow p\\approx 0.0155$ (**significant**).\n",
    "\n",
    "**(I.3) Power for $\\mu_1=\\mu_2+8$ at $\\alpha=5\\%$, true $\\sigma^2=16$ (both), $n_1=n_2=10$**  \n",
    "Noncentral t with $\\text{ncp}=\\dfrac{8}{4\\sqrt{1/10+1/10}}=4.472$; power $\\approx \\mathbf{98.8\\%}$.  \n",
    "**Answer category:** $P_{\\text{detect}}\\ge 75\\%$ (Option 1).\n",
    "\n",
    "**(I.4) Paired scheme (each subject wears both soles)**  \n",
    "Statements 1–3 are **false** (pairing typically **increases** power; decreasing $\\alpha$ to 1% **reduces** power).  \n",
    "**Answer:** None of the above (Option 5).\n",
    "\n",
    "**Reproducible Python (assumes helper functions defined earlier)**\n",
    "~~~python\n",
    "y1bar, y2bar, s1, s2, n1, n2 = 11.9, 17.8, 6.2, 3.2, 10, 10\n",
    "\n",
    "F, df1, df2, pF_two = f_test_variances(s1, n1, s2, n2)  # ~ p=0.062\n",
    "t0, df, p = two_sample_t_equal(y1bar, s1, n1, y2bar, s2, n2)  # p ~ 0.0155\n",
    "\n",
    "power = power_two_sample_equal(delta=8, sigma=4, n1=10, n2=10, alpha=0.05)  # ~ 0.988\n",
    "~~~\n",
    "\n",
    "---\n",
    "\n",
    "## Problem I — Cosmetics (Hand Crème)\n",
    "\n",
    "Independent groups: $n_{\\text{New}}=n_{\\text{Old}}=8,\\ \\bar{y}_{\\text{Old}}=19.3,\\ \\bar{y}_{\\text{New}}=22.1,\\ s_{\\text{Old}}=2.4,\\ s_{\\text{New}}=4.2$.\n",
    "\n",
    "**(I.1)** $H_0:\\sigma_{\\text{New}}^2=\\sigma_{\\text{Old}}^2$ vs $H_1:\\sigma_{\\text{New}}^2>\\sigma_{\\text{Old}}^2$  \n",
    "$F_0=(4.2^2)/(2.4^2)=3.0625$, df $(7,7)$ → one-sided $p\\approx 0.0815$.  \n",
    "**Minimum $\\alpha$ to reject:** 10% (Option 4).\n",
    "\n",
    "**(I.2)** Means: $H_0:\\mu_{\\text{New}}=\\mu_{\\text{Old}}$ vs $H_1:\\mu_{\\text{New}}>\\mu_{\\text{Old}}$ (pooled t)  \n",
    "$t_0\\approx 1.64,\\ \\mathrm{df}=14\\Rightarrow p_{\\text{one-sided}}\\approx 0.062$.\n",
    "\n",
    "**Switch to paired design (one hand each formula)**  \n",
    "Differences (New–Old): $[1.4,\\,1.6,\\,-0.3,\\,2.0,\\,-0.4,\\,1.8,\\,0.8,\\,1.1]$.\n",
    "\n",
    "**(I.3) Which statement is correct?**  \n",
    "$\\mathrm{df}=n-1=7$ (not 6); pairing doesn’t **guarantee** significance; fewer subjects ≠ impossible.  \n",
    "**Answer:** None of the above (Option 4).\n",
    "\n",
    "**(I.4) Two-sided paired test**  \n",
    "$\\bar{d}=1.00,\\ s_d\\approx 0.915,\\ t_0\\approx 3.09,\\ \\mathrm{df}=7\\Rightarrow p\\approx 0.0175$ (**significant**).\n",
    "\n",
    "**Reproducible Python (assumes helper functions defined earlier)**\n",
    "~~~python\n",
    "# Independent-phase answers\n",
    "s_old, s_new, n_old, n_new = 2.4, 4.2, 8, 8\n",
    "F, df1, df2, p_one = f_test_variances(s_new, n_new, s_old, n_old, alternative=\"greater\")  # ~ 0.0815\n",
    "\n",
    "y_old, y_new = 19.3, 22.1\n",
    "t0, df, p_one = two_sample_t_equal(y_new, s_new, n_new, y_old, s_old, n_old, alternative=\"greater\")  # ~ 0.062\n",
    "\n",
    "# Paired-phase answers\n",
    "new = np.array([21.7,22.4,22.7,20.8,18.2,16.5,18.8,26.2])\n",
    "old = np.array([20.3,20.8,23.0,18.8,18.6,14.7,18.0,25.1])\n",
    "dbar, sd, t0, df, p_two = paired_t(new-old)  # t ~ 3.09, df=7, p ~ 0.0175\n",
    "~~~\n",
    "\n",
    "---\n",
    "\n",
    "# 11) Factorial ANOVA Quick Example (Your Problem II)\n",
    "\n",
    "Design: $A\\times B\\times C$ with levels $a=2,\\ b=4,\\ c=5$, replicated $r=2$ times → $N=80$.  \n",
    "Given sums of squares (SS):  \n",
    "$\\text{SSA}=24,\\ \\text{SSB}=14,\\ \\text{SSC}=42,\\ \\text{SS}_{AB}=6,\\ \\text{SS}_{AC}=16,\\ \\text{SS}_{BC}=12,\\ \\text{SS}_{ABC}=16,\\ \\text{SS}_{\\text{Total}}=165$.\n",
    "\n",
    "Assume the **model includes only main effects and two-factor interactions** (so the three-way SS is pooled into error with within-cell replication error).\n",
    "\n",
    "**Degrees of freedom**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\mathrm{df}_A=a-1=1,\\quad \\mathrm{df}_B=b-1=3,\\quad \\mathrm{df}_C=c-1=4,\\\\\n",
    "&\\mathrm{df}_{AB}=(a-1)(b-1)=3,\\quad \\mathrm{df}_{AC}=4,\\quad \\mathrm{df}_{BC}=12,\\\\\n",
    "&\\mathrm{df}_{ABC}=(a-1)(b-1)(c-1)=12,\\\\\n",
    "&\\mathrm{df}_{\\text{pure err}}=abc(r-1)=2\\cdot4\\cdot5\\cdot1=40,\\\\\n",
    "&\\mathrm{df}_{\\text{error (pooled)}}=40+12=52,\\\\\n",
    "&\\mathrm{df}_{\\text{total}}=N-1=79.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Error SS (pooled) and MSE**\n",
    "$$\n",
    "\\mathrm{SSE}=165-(24+14+42+6+16+12)=51,\\qquad\n",
    "\\mathrm{MSE}=\\frac{51}{52}\\approx 0.9808.\n",
    "$$\n",
    "\n",
    "**Mean squares & F**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\text{MSA}=24/1=24 \\Rightarrow F_A=\\frac{24}{0.9808}\\approx 24.47\\ (p\\approx 8.3\\times 10^{-6})\\\\\n",
    "&\\text{MSB}=14/3 \\Rightarrow F_B\\approx 4.76\\ (p\\approx 0.0053)\\\\\n",
    "&\\text{MSC}=42/4 \\Rightarrow F_C\\approx 10.71\\ (p\\approx 2.1\\times 10^{-6})\\\\\n",
    "&\\text{MS}_{AB}=6/3 \\Rightarrow F_{AB}\\approx 2.04\\ (p\\approx 0.120)\\\\\n",
    "&\\text{MS}_{AC}=16/4 \\Rightarrow F_{AC}\\approx 4.08\\ (p\\approx 0.0060)\\\\\n",
    "&\\text{MS}_{BC}=12/12 \\Rightarrow F_{BC}\\approx 1.02\\ (p\\approx 0.445).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Interpretation (at $\\alpha=0.05$):** A, B, C, and AC are **significant**; AB and BC are **not**.\n",
    "\n",
    "**Python to verify**\n",
    "~~~python\n",
    "from scipy import stats as st\n",
    "SSA, SSB, SSC, SSAB, SSAC, SSBC, SSABC, SST = 24, 14, 42, 6, 16, 12, 16, 165\n",
    "a,b,c,r = 2,4,5,2\n",
    "dfA, dfB, dfC = a-1, b-1, c-1\n",
    "dfAB, dfAC, dfBC = (a-1)*(b-1), (a-1)*(c-1), (b-1)*(c-1)\n",
    "dfABC = (a-1)*(b-1)*(c-1)\n",
    "df_total = a*b*c*r - 1\n",
    "df_error = df_total - (dfA+dfB+dfC+dfAB+dfAC+dfBC)\n",
    "SSE = SST - (SSA+SSB+SSC+SSAB+SSAC+SSBC)\n",
    "MSE = SSE/df_error\n",
    "\n",
    "def F_p(F, dfn, dfd): return 1-st.f.cdf(F, dfn, dfd)\n",
    "\n",
    "effects = {\n",
    " \"A\": (SSA/dfA, dfA),\n",
    " \"B\": (SSB/dfB, dfB),\n",
    " \"C\": (SSC/dfC, dfC),\n",
    " \"AB\": (SSAB/dfAB, dfAB),\n",
    " \"AC\": (SSAC/dfAC, dfAC),\n",
    " \"BC\": (SSBC/dfBC, dfBC),\n",
    "}\n",
    "for k, (MS, dfn) in effects.items():\n",
    "    F = MS/MSE\n",
    "    print(k, F, F_p(F, dfn, df_error))\n",
    "~~~\n",
    "\n",
    "---\n",
    "\n",
    "# 12) Assumptions Checklist & Diagnostics\n",
    "\n",
    "- **Independence:** design & data collection (randomization, no hidden pairing).  \n",
    "- **Normality (for $t/\\chi^2/F$):** QQ plot on residuals (or within groups). With $n\\gtrsim 30$, t-methods are robust.  \n",
    "- **Equal variances:** boxplots, residual‐vs‐fitted, F-test (sensitive), or Levene’s test (more robust).  \n",
    "- **No severe outliers:** check plots; consider robust methods/transformations if needed.\n",
    "\n",
    "---\n",
    "\n",
    "# 13) Quick “Cheat Sheets”\n",
    "\n",
    "**Choosing a test (two means)**  \n",
    "- Independent? **Yes** → Equal variances plausible?  \n",
    "  – Yes → **pooled** two-sample t  \n",
    "  – No → **Welch** t  \n",
    "- Paired/blocked? **Yes** → **Paired** t\n",
    "\n",
    "**Two-sided P-values**  \n",
    "- $t$ or $Z$: $2\\big[1-F(|\\text{stat}|)\\big]$.  \n",
    "- $F$ or $\\chi^2$: use appropriate tail(s) per $H_1$.\n",
    "\n",
    "**Margin of error (two-sample, equal $n$)**\n",
    "$$\n",
    "\\text{ME}=t_{\\alpha/2,\\,2n-2}\\;s_p\\sqrt{\\frac{2}{n}}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 14) Extra: Discrete Distributions — Mean & Variance\n",
    "\n",
    "For a discrete rv $X$ with pmf $p(x)$:\n",
    "$$\n",
    "E[X]=\\sum_x x\\,p(x),\\qquad\n",
    "\\operatorname{Var}(X)=\\sum_x (x-E[X])^2\\,p(x).\n",
    "$$\n",
    "\n",
    "**Example (Python)**\n",
    "~~~python\n",
    "# Discrete pmf on {0,1,2} with p = {0.2, 0.5, 0.3}\n",
    "x = np.array([0,1,2], float)\n",
    "p = np.array([0.2,0.5,0.3], float)\n",
    "mu = (x*p).sum()\n",
    "var = ((x-mu)**2 * p).sum()\n",
    "mu, var\n",
    "~~~\n",
    "\n",
    "---\n",
    "\n",
    "# 15) Extra: CIs & Hypothesis Tests (One-Sample Refresh)\n",
    "\n",
    "**Mean, $\\sigma$ unknown (normal or large $n$)**\n",
    "$$\n",
    "\\bar{y}\\ \\pm\\ t_{\\alpha/2,\\,n-1}\\frac{s}{\\sqrt{n}},\n",
    "\\qquad\n",
    "t_0=\\frac{\\bar{y}-\\mu_0}{s/\\sqrt{n}}\\sim t_{n-1}.\n",
    "$$\n",
    "\n",
    "**Variance**\n",
    "$$\n",
    "\\chi_0^2=\\frac{(n-1)s^2}{\\sigma_0^2}\\sim \\chi^2_{n-1},\\qquad\n",
    "\\text{CI as in §5.1}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 16) Sanity-Check Plots (Python)\n",
    "\n",
    "~~~python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def quick_plots(sample1, sample2, labels=(\"Group 1\",\"Group 2\")):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot([sample1, sample2], labels=labels, showmeans=True)\n",
    "    ax.set_title(\"Boxplots with means\")\n",
    "    plt.show()\n",
    "\n",
    "def qq_plot(sample, label=\"Sample\"):\n",
    "    import statsmodels.api as sm\n",
    "    sm.qqplot(np.asarray(sample), line='s')\n",
    "    plt.title(f\"QQ plot - {label}\")\n",
    "    plt.show()\n",
    "~~~\n",
    "\n",
    "*Tip:* Don’t overthink colors/styles for study notes. Focus on **shape**, **spread**, and **outliers**.\n",
    "\n",
    "---\n",
    "\n",
    "# 17) Summary (What to remember)\n",
    "\n",
    "- Use **paired** designs whenever you can (block what you can’t randomize).  \n",
    "- Plot first; check **normality/variance** assumptions before relying on $t/F/\\chi^2$.  \n",
    "- Prefer **Welch** when variances look unequal.  \n",
    "- Report **effect size + CI** (interpretation!) alongside P-values.  \n",
    "- For planning, connect **effect size**, **power**, and **sample size**.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
